{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Exploratory Data Analysis (4 Pts)\n",
    "Download and explore the data. Explore label distribution and qualitatively describe the data by\n",
    "plotting healthy and pneumonia samples. Do you see visual differences between healthy and\n",
    "disease samples? Do you find sources of bias that could influence model performance? How do\n",
    "you preprocess the data for your further analysis?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and explore the data. Explore label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of healthy samples: 1342\n",
      "Number of bacterial pneumonia samples: 2530\n",
      "Number of viral pneumonia samples: 1345\n"
     ]
    }
   ],
   "source": [
    "def count_samples(dir_path, filter_phrase=\"\"):\n",
    "    count = 0\n",
    "    # Iterate directory\n",
    "    for path in os.listdir(dir_path):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path, path)):\n",
    "            if filter_phrase in os.path.basename(path):\n",
    "                count += 1\n",
    "    #account for duplicate Identifier files\n",
    "    return int(count/2)\n",
    "\n",
    "\n",
    "print(f\"Number of healthy training samples: {count_samples(r'chest_xray/train/NORMAL')}\")\n",
    "phrase = \"bacteria\"\n",
    "print(f\"Number of bacterial pneumonia training samples: {count_samples(r'chest_xray/train/PNEUMONIA', phrase)}\")\n",
    "phrase = \"virus\"\n",
    "print(f\"Number of viral pneumonia training samples: {count_samples((r'chest_xray/train/PNEUMONIA'), phrase)}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and qualitatively describe the data by plotting healthy and pneumonia samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see visual differences between healthy and disease samples?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you find sources of bias that could influence model performance?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you preprocess the data for your further analysis?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: CNN Classifier (4 Pts)\n",
    "In Q3 and Q4, we aim to use post-hoc explainability methods for visualizing the parts of the image that are important for the prediction of a model. Thus, design a small CNN classifier for the dataset and report its performance on a test set. Make sure to elaborate on your architecture and training details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "design a small CNN classifier for the dataset and report its performance on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to elaborate on your architecture and training details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Integrated Gradients5 (4 Pts)\n",
    "Like MLPs, CNNs perform very well in tasks like classification but lack interpretability due to their black-box nature. Again, post-hoc explainability methods are thus suitable alternatives.\n",
    "One class of post-hoc procedures specific to image data are methods generating attribution\n",
    "maps, which try to highlight the most important regions on which the CNN bases its predictions.\n",
    "For this part of the assignment, implement the integrated gradient method. Visualize attribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the assignment, implement the integrated gradient method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Grad-CAM6 (5 Pts)\n",
    "Grad-CAM is another post-hoc method that generates attribution maps. Like in Q3, implement\n",
    "the method and visualize attribution maps of five healthy and five disease test samples. Do the maps highlight sensible regions? Are attributions consistent across samples? Compare your\n",
    "findings with Q3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize attribution maps of five healthy and five disease test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the maps highlight sensible regions?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are attributions consistent across samples?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare your findings with Q3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Data Randomization Test7 (3 Pts)\n",
    "Recently, the paper “Sanity Checks for Saliency Maps.” introduced the data randomization test\n",
    "to check how trustworthiness of the saliency maps of specific methods. They propose to retrain\n",
    "the classifier on the train set when randomly permuting labels of all samples. Then, they\n",
    "compare the saliency maps on test samples for the perturbed and unperturbed classifiers. We\n",
    "expect the map to change if an attribution map accurately captures the relationship between\n",
    "instances and their labels. Conversely, if the attribution map captures another concept, e.g., acts\n",
    "like an edge detector independent of the label, we expect the maps to stay the same. Retrain\n",
    "your CNN on random training labels and perform the Data randomization Test for both\n",
    "Integrated Gradients and Grad-CAM. Do they pass or fail? Elaborate and visualize your\n",
    "findings!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain your CNN on random training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform the Data randomization Test for both Integrated Gradients and Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do they pass or fail?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborate and visualize your findings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge 2: Prototype Learning (10 Pts)\n",
    "A radically different idea for interpretable classification is finding prototypical samples for each\n",
    "class. Then, in addition to the prediction, we can return the prototype most similar to the input.\n",
    "This idea was explored in the paper “Examples are not Enough, Learn to Criticize! Criticism for\n",
    "Interpretability”8. They provide a method that allows you to extract representative prototypes\n",
    "from a given dataset by using the maximum mean discrepancy (MMD) measure as a distance\n",
    "function and introducing a kNN-like classifier. After reading the paper, we ask you to implement\n",
    "their method in two steps:\n",
    "1.\n",
    "Implement the “Nearest Prototype Classifier” described in Section 5 of the paper. For\n",
    "now, set the set of prototypes S to be random points of the training set. Report the\n",
    "classification performance of this model on the test set.\n",
    "2.\n",
    "Implement the function Jb(S) (Section 3) and select prototypes S through their greedy\n",
    "algorithm (Algorithm 1). Refit the classifier, this time with the selected prototypes, and\n",
    "compare classification performance to random prototypes. Does the result behave as\n",
    "you expected? Why or why not? Visualize five healthy and five disease prototypes. Do\n",
    "you find representative class patterns among them? Would you say they look\n",
    "prototypical?\n",
    "How could you improve performance beyond simply applying kNN to the raw images? Compare\n",
    "this type of interpretable method to the previously seen saliency maps. Which method do you\n",
    "think is more useful? Can you think of scenarios where one is more valuable than the other?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the “Nearest Prototype Classifier” described in Section 5 of the paper. For\n",
    "now, set the set of prototypes S to be random points of the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the classification performance of this model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function Jb(S) (Section 3) and select prototypes S through their greedy\n",
    "algorithm (Algorithm 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit the classifier, this time with the selected prototypes, and\n",
    "compare classification performance to random prototypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the result behave as you expected? Why or why not?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize five healthy and five disease prototypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you find representative class patterns among them? Would you say they look\n",
    "prototypical?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could you improve performance beyond simply applying kNN to the raw images? Compare\n",
    "this type of interpretable method to the previously seen saliency maps. Which method do you\n",
    "think is more useful? Can you think of scenarios where one is more valuable than the other?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "23fs_mlhc_p1-BKWt2mVv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
